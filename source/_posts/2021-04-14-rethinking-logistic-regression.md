title: 深入思考逻辑回归
subtitle: 温故而知新，重新梳理、思考、学习逻辑回归
cover: ##
tags:
  - 人工智能
  - AI
categories: 人工智能
author:
  nick: hyde
  github_name: hydchow
date: 2021-04-14 18:31:19

---

## 问题背景
假设有这样的一个需求：判断某一朵花是不是鸢尾花。我们知道不同品种的花，其长得是不一样，所以我们可以通过花的若干外观特征（花萼长度、花萼宽度、花瓣长度、花瓣宽度等）来表示这一朵花。
基于这个思路，我们采集N朵花并对其标注，得到以下的数据集。
![图片](https://img14.360buyimg.com/imagetools/jfs/t1/159980/14/19133/19237/6076d5cbEd46d57d7/2a50a3925e70e9b0.png)

考虑最简单的一种情形，Y(是否为鸢尾花)，与特征X线性相关，W定义为相关系数，即模型F可以用下面公式表述：

![图片](https://img11.360buyimg.com/imagetools/jfs/t1/162526/5/18129/2095/6076d690Ecb45eaca/dafd777878bbe1fd.png)

化简写成向量化形式：![图片](https://img13.360buyimg.com/imagetools/jfs/t1/165302/4/18367/1444/6076d71bE95dc78e9/8427ca2cdf6f8f32.png)，也就是线性回归，![图片](https://img11.360buyimg.com/imagetools/jfs/t1/159939/8/19521/1381/6076d76dE5a646e25/b60bc3361cf7fbdc.png)

现在问题来了，是和否是两种状态，在计算机科学上我们常用1/0开关量来表述，但是从表示式的值域上看数学公式: ![图片](https://img13.360buyimg.com/imagetools/jfs/t1/158005/14/19394/974/6076d82fEae65e74a/565e84622a1fe77e.png) 能取任意值，这是没办法直接成表述0/1开关量。那如何解决这个问题呢？通过一个转换函数(又称为激活函数)，将线性回归转换逻辑回归。 
![图片](https://img10.360buyimg.com/imagetools/jfs/t1/161952/20/18527/1907/6076d832E6d6543ea/2fe426c44008b6fa.png)

## 建模思路
并不是任意函数都可以作激活函数使用的，激活函数具有以下几种良好的性质：  
<font color='red'>非线性</font>，线性函数的复合线性函数仍是线性函数，故线性激活函数不能带来非线性的变换，使用这样激活函数不能增强模型的表达能力，如此一来就没办法拟合复杂的实现问题了，所以激活函数必须非线性的。  
<font color='red'>连续可微</font>，如果函数不可微分，就没办法通过梯度下降法来迭代优化，以得到近似的最优解了。如果激活函数不可微，可能需要其他各复杂的数学工具来求解，一是未必会有解，二是计算成本太高，难以实现和落地。  
<font color='red'>单调性</font>，线性函数本身是单调，这个本身是一定的物理意义的，所以经过激活函数转换后也保持这个性质，不能改变其单调性。 满足![图片](https://img10.360buyimg.com/imagetools/jfs/t1/165664/10/18387/2508/6076d94bEdc50a9b1/9d3cb8648a211a0a.png)

### 直接转换
通过一个分段函数，把f(x)直接映射成0或1，如公式所示：  
![图片](https://img12.360buyimg.com/imagetools/jfs/t1/169528/15/18381/2833/6076d9d3E57132c66/cff07286448bb63b.png)  
但是，这个分段函数不连续不可微不单调，还带一个额外的参数k，所以这种分段函数并不适合作激活函数使用。

### 间接映射
不直接映射成0或1，而是将f(x)的值域压缩到(0,1)之间，如公式所示：  
![图片](https://img12.360buyimg.com/imagetools/jfs/t1/165669/26/18594/1981/6076da34E8eace2dc/1812a91a76daa672.png)   
这就是sigmoid函数了，下图为sigmoid函数的图像。  
![图片](https://img13.360buyimg.com/imagetools/jfs/t1/161938/38/18558/45163/6076d4d5Ea22e16ba/b6ba3dd818cd57b4.png)   
显然是这个函数是具有上面提到的激活函数的三种优良性质。同时将输出压缩到(0,1)区间上，有一个很直观感受是，我们可以把这个输出值理解为一种概率，在这个问题上指的是鸢尾花的概率，当这个概率值大于0.5，说明鸢尾花概率大即1，反之则不是鸢尾花即0，这就能实现分类的判别了。

## 实现逻辑
那既然现在有了sigmoid激活函数，我们该利用它训练模型呢？<font color='red'>模型之所以能训练是依赖于两个神器:损失函数和梯度下降，前者能量化我们模型预测与真实结果的误差、确定优化的目标函数，后者能知道如何去减少误差、具体地优化目标函数</font>。

### 损失函数
sigmoid激活函数输出值可以看作是概率，具体地我们可以把这个概率，看成是预测结果为是的概率。  
![图片](https://img12.360buyimg.com/imagetools/jfs/t1/172295/17/4135/2364/6076db2bE4d2e1c06/56e646d53237c3f7.png)   
我们需要预测的分类结果要么为是要么为否，只有两种情况，显然样本X是服从伯努利(0-1)分布。假定样本X，当分类标签真值y为1时，我们就看y_pred也是sigmoid的输出值（模型预测为是的概率），0是1的互斥事件，当分类标签真值为0时，我们就看1-y_pred（模型预测为否的概率），所以条件概率P(Y|X)可以量化出模型预测的准确程度了。  
![图片](https://img12.360buyimg.com/imagetools/jfs/t1/162964/31/19425/2667/6076db64E91f6ca3a/ed217f5bff559681.png)  
合并化简，整合成统一形式  
![图片](https://img10.360buyimg.com/imagetools/jfs/t1/170001/26/18545/2160/6076dbc1E8438bedb/61fe18086ce8b60d.png)  
P(Y|X)就是模型预测结果，显然P(Y|X)的值越接近于1，说明模型预测结果越准。一个数据集有N个样本，每个样本之间独立的，所以在模型在整个数据上好坏，可以这样定义：  
![图片](https://img12.360buyimg.com/imagetools/jfs/t1/166877/1/18837/4990/6076dc2cEb4334041/9e31a859c9959c31.png)  
显然，要使得模型得效果最佳，则得找到一个最佳参数![图片](https://img13.360buyimg.com/imagetools/jfs/t1/162705/24/18434/839/6076dc26E99d1b894/bb359c62fa1461a0.png)使得![图片](https://img11.360buyimg.com/imagetools/jfs/t1/160500/15/19120/1720/6076dc31Eeecd8a59/0559ea6396285156.png)能取到最大值，这个就是最优化方法里面的极大使然估计(MLE)了，我们找到损失函数了。  
![图片](https://img14.360buyimg.com/imagetools/jfs/t1/167463/23/18382/2866/6076dcddE71b550ff/4b8ad513b6f306a8.png)  
接下来，我们得看看如何转换这个损失函数：<font color='red'>加负号（最大值问题转化最小值问题，梯度下降能找最小值），取对数（不改单调性，把复杂的连乘变成简单的连加）</font>
![图片](https://img11.360buyimg.com/imagetools/jfs/t1/167421/29/18421/5797/6076dce3E09aecd3f/fdbd72a04d0abb5e.png)

### 梯度下降
确定了目标函数之后，接下来就可以利用梯度下降，用迭代更新参数W，使其不断逼近目标函数的极值点。  
![图片](https://img12.360buyimg.com/imagetools/jfs/t1/170395/38/18486/5597/6076dd96E0ec2fbc0/01f02dba757fd1ed.png)  
梯度推导：  
![图片](https://img13.360buyimg.com/imagetools/jfs/t1/170133/15/18681/24740/6076dddfEb55a269e/a7c373ba30de9a89.png)  
联立式②③可见  
![图片](https://img10.360buyimg.com/imagetools/jfs/t1/162909/4/18209/18592/6076de44E4b740042/ae535fd90150fb0d.png)  
由此可见，t+1时刻模型预测误差总会比在t时刻更小，通过这样迭代，模型就能不断学习和调整，一直到偏导数为0的(局部)最优极值点，这时候参数便无法再继续调整了，模型也就停止再训练了。

## 结语
逻辑回归(Logistic Regression)是机器学习上面一个最简单、最基础的模型框架和基本范式，不夸张地说它是机器学习奠基石之一，后续的机器学习模型，很多都是立足于这个基础的模型框架上，提出各种形式拓展与改进。  
深刻地理解逻辑回归模型，梳理逻辑回归模型背后建模思路、因果缘由、实现逻辑，能让我们对机器学习的方法论有一个更全面更清晰的认知。


